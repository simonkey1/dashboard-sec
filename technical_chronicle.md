# Cr√≥nica T√©cnica: Anatom√≠a de una Infraestructura de Investigaci√≥n

Este documento narra la evoluci√≥n t√©cnica del proyecto, desde un monitor en tiempo real hasta una infraestructura de datos de alto rendimiento para investigaci√≥n acad√©mica.

## üìú Tabla de Contenidos
1. [El Origen: El Muro de las IP](#1-el-origen-el-muro-de-las-ip)
2. [El Pivote: Local-First y Asincron√≠a](#2-el-pivote-local-first-y-asincron√≠a)
3. [Arquitectura Medall√≥n: Del Caos al Oro](#3-arquitectura-medall√≥n-del-caos-al-oro)
4. [Transparencia de Datos y EDA](#4-transparencia-de-datos-y-eda)
5. [Metodolog√≠a de Estimaci√≥n de Clientes](#5-metodolog√≠a-de-estimaci√≥n-de-clientes)

---

## 1. El Legado: Arquitectura Real-Time (2017-2024)

Esta secci√≥n documenta la arquitectura original de monitoreo continuo, dise√±ada para operar 24/7 antes del pivote hacia la investigaci√≥n hist√≥rica. Aunque gran parte de este c√≥digo hoy vive en `scripts/legacy/`, sus patrones de dise√±o fueron fundamentales para entender la naturaleza del dato.

### 1.1 Dise√±o de Alta Disponibilidad & Resiliencia
El objetivo era mantener un "latido" constante del sistema el√©ctrico. Para lograrlo en un entorno hostil (bloqueos de IP, timeouts), implementamos patrones de estabilidad robustos.

#### üõ°Ô∏è Circuit Breaker Pattern
Para evitar la saturaci√≥n del servidor origen y prevenir bloqueos de IP por fuerza bruta, implementamos un **Circuit Breaker** (`core/circuit_breaker.py`).
- **L√≥gica**: Si el scraper detectaba 5 fallos consecutivos (HTTP 500/503 o cambios en el DOM), el circuito se "abr√≠a".
- **Efecto**: El sistema entraba en modo de espera por 30 minutos ("Cooldown"), rechazando cualquier intento nuevo de scraping hasta que el origen se estabilizara.
- **Evidencia**: Los tests unitarios en `tests/unit/test_circuit_breaker.py` validan esta transici√≥n de estados (CLOSED -> OPEN -> HALF-OPEN).

### 1.2 Monitoreo: Fail-Fast & Logs
En un sistema desatendido, el silencio es el peor error. Implementamos una estrategia de **Fail-Fast**:
- **Logs Estructurados**: Cada paso del pipeline emit√≠a logs con contexto (Timestamp, Stage, ErrorCode).
- **Detecci√≥n de Cambios**: Si la estructura HTML de la SEC cambiaba (algo com√∫n), el parser fallaba inmediatamente en lugar de ingerir datos corruptos (`Fast-Fail`).
- **Health Checks**: Scripts auxiliares (`core/health_check.py`) verificaban peri√≥dicamente que el proceso estuviera vivo y escribiendo en la base de datos.

### 1.3 Gesti√≥n de Datos: Almacenamiento Infinito
Con un presupuesto de almacenamiento limitado en la nube, no pod√≠amos guardar todo para siempre.
- **Ventana Deslizante**: La base de datos estaba dise√±ada para mantener solo 30 d√≠as de "datos calientes" para el dashboard en tiempo real.
- **Cleanup Autom√°tico**: El script `scripts/legacy/cleanup_old_data.py` se ejecutaba cronol√≥gicamente para:
    1.  Archivar datos antiguos en formato comprimido (Cold Storage).
    2.  Eliminar registros raw de la BD operacional para mantener los √≠ndices ligeros.

### 1.4 Estrategia de Testing H√≠brida
Mantuvimos una estricta separaci√≥n de responsabilidades en las pruebas:
- **Unitarias (`tests/unit/`)**: Validaci√≥n aislada de componentes l√≥gicos (ej. ¬øEl Circuit Breaker se abre correctamente?).
- **Integraci√≥n (`tests/integration/`)**: Validacion del flujo completo, incluyendo la conexi√≥n a base de datos y la ejecuci√≥n real del cleanup de archivos.

> [!NOTE]
> Para detalles de implementaci√≥n, ver los scripts en `scripts/legacy/` o consultar el [README.md](../README.md) principal.

---

## 2. El Pivote: Local-First y Asincron√≠a
La necesidad de datos hist√≥ricos para una investigaci√≥n acad√©mica de largo plazo (2017-2025) forz√≥ un redise√±o radical. Abandonamos la idea del "ETL continuo en la nube" por un enfoque **Historical Sync Local**.

### Ventajas del Cambio
- **Bypass de Bloqueos**: El scraping desde conexiones residenciales locales result√≥ ser m√°s resiliente que desde datacenters.
- **Simplificaci√≥n**: En lugar de mantener una base de datos "viva" 24/7 con alto costo, optamos por procesar archivos mensuales pesados en r√°fagas.
- **Velocidad**: Implementamos un motor as√≠ncrono en Python (`aiohttp` + `asyncio`) que redujo el tiempo de procesamiento de horas a minutos.

---

## 3. Arquitectura Medall√≥n: Del Caos al Oro
Para manejar los ~6.2 millones de registros, implementamos una **Arquitectura Medall√≥n** (Medallion Architecture) adaptada a almacenamiento infinito gratuito.

```mermaid
graph TD
    A[Bronze: Raw Snapshots] -->|Deduplicaci√≥n & Hash MD5| B(Silver: Clean Fact Table)
    B -->|Pre-agregaci√≥n Polars| C[Gold: Analysis Ready - Supabase]
    C -->|Vistas de 30 d√≠as| D[An√°lisis Real-Time]
    C -->|Historical Parquet| E[Investigaci√≥n Acad√©mica]
```

- **Bronze Layer**: Guardamos todo el historial raw en la nube (almacenamiento de bajo costo/gratuito).
- **Silver Layer**: PostgreSQL local donde vive la `fact_interrupciones` deduplicada.
- **Gold Layer**: Vistas optimizadas y JSONs pre-calculados que se suben a Supabase para alimentar el frontend. Esto nos da "almacenamiento infinito" en t√©rminos de an√°lisis, ya que solo mantenemos lo justo y necesario para la visualizaci√≥n activa.

---

## 4. Transparencia de Datos y EDA
La base de nuestra investigaci√≥n es la transparencia. Aqu√≠ presentamos un breve an√°lisis exploratorio (EDA) de nuestra base de datos.

### 4.1 Calidad de los Datos de Interrupciones
La visualizaci√≥n (Figura 1) muestra una **ausencia total de valores nulos** en la base de datos final. Esto no es accidental, sino resultado de una estrategia de **Defensive Ingestion** en la capa ETL `AsyncPostgreSQLRepository`.

#### Reglas de Imputaci√≥n (Hard Rules)
Para evitar corromper la tabla de hechos con datos sucios, aplicamos las siguientes transformaciones *antes* de la inserci√≥n. En el corte actual (Total: **731,666 eventos**), la incidencia de estas reglas fue:

1.  **Clientes Afectados**: Si el campo viene vac√≠o o nulo, se imputa con `0`.
    *   *Incidencia Real*: **0 casos (0.00%)**. La fuente de datos ha demostrado ser consistente en este campo cr√≠tico.
2.  **Geograf√≠a/Empresa**: Si el ID de Comuna o Empresa no resuelve contra las dimensiones en cach√©, se asigna el ID correspondiente a `"DESCONOCIDO"`.
    *   *Incidencia Real*: **0 casos (0.00%)**. Todas las comunas y empresas reportadas mapearon exitosamente a nuestros diccionarios maestros.
3.  **Fechas**: Si la `fecha_inicio` no es parseable, se usa el `timestamp_server` como fallback.

Este pre-procesamiento estricto explica la limpieza del dataset: **las reglas de imputaci√≥n actuaron como "Guardrails" latentes**, garantizando que cualquier anomal√≠a futura sea capturada sin detener el pipeline.

> [!NOTE]
> **Hip√≥tesis de Calidad en el Origen**: La consistencia perfecta (0 errores de integridad referencial) indica que el endpoint p√∫blico de la SEC **no expone datos crudos de sensores**, sino que sirve una vista ya procesada y validada por sus propios sistemas internos. Consumimos, en efecto, un dato "Pre-Silver".

### 4.2 El Cruce con Proyectos (SEIA)
Para validar si la inversi√≥n ayuda a la fiabilidad, cruzamos los datos de cortes con la base de proyectos del SEIA relacionados con electricidad.

![Distribuci√≥n Proyectos](figures/eda_projects_dist.png)
*Figura 2: Distribuci√≥n de proyectos de inversi√≥n el√©ctrica analizados para el estudio.*

> [!NOTE]
> **Miner√≠a vs Energ√≠a**: Aunque la Regi√≥n de Antofagasta est√° dominada por la miner√≠a, los proyectos aqu√≠ contabilizados son exclusivamente del **Sector Energ√≠a** (L√≠neas de Transmisi√≥n, Subestaciones, BESS). Es com√∫n que empresas mineras (ej: *Minera Spence*) act√∫en como titulares de estos proyectos para abastecer sus faenas, pero t√©cnicamente constituyen infraestructura el√©ctrica.

---

## 5. Metodolog√≠a de Estimaci√≥n de Clientes
Determinar la gravedad de un corte requiere dos cifras: el numerador (afectados) y el denominador (total de clientes). Utilizamos endpoints distintos de la SEC para cada uno:

### A. Denominador: Universo de Clientes (`GetClientesRegional`)
Para calcular m√©tricas normalizadas (como usuarios afectados por cada 1000 clientes), necesitamos el total de medidores por regi√≥n.
- **Fuente**: Endpoint `/GetClientesRegional`.
- **Frecuencia**: Scrapeo mensual (ver `scripts/scrapers/scrape_clientes_region.py`).
- **Uso**: Define la "poblaci√≥n base" de la regi√≥n en ese mes.

### B. Numerador: Afectaci√≥n Instant√°nea (`GetPorFecha`)
Es el dato "vivo". Proviene del campo `Clientes` dentro del payload JSON de cada interrupci√≥n.
- **Validaci√≥n**: Comparamos este valor contra el total regional. Si un evento reporta m√°s afectados que el total de la regi√≥n (anomal√≠a detectada en < 0.01% de casos), se hace *cap* al total regional.

### C. El Algoritmo de "Afectaci√≥n Neta"
Un corte de luz no es est√°tico; evoluciona. 
> *Ejemplo: A las 14:00 hay 500 afectados. A las 14:10 hay 1000. A las 14:20 bajan a 200.*

Nuestra m√©trica de "Clientes Afectados" para el evento (identificado por `hash_id`) se define como el **M√°ximo Hist√≥rico (High-Water Mark)** registrado durante la vida del evento. Esto previene subestimar la magnitud del incidente si el scraper captura el evento justo cuando se est√° resolviendo.

---

> [!TIP]
> Todo el c√≥digo de esta infraestructura est√° disponible en `scripts/etl/` y `scripts/analysis/`.
